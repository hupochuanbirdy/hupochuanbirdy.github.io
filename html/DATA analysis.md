### Data analysis æ•°æ®åˆ†æ No1

## 1. Pandas

### Series

`Series` is a one-dimensional array with axis labels. There are multiple ways to create an array. 

```python
import pandas as pd
myseries = pd.Series([10, 20, 30])
print(myseries)


#=====Output======
0    10
1    20
2    30
dtype: int64
#=================
```

### DataFrame

`DataFrame` is the two-dimensional data structure of Pandas. It consists of labeled rows and columns.

```python
import pandas as pd

df = pd.DataFrame({
    "Name": ["Jane", "John", "Matt", "Ashley"],
    "Age": [24, 21, 26, 32]
})
print(df)

#======Output====
   Age    Name
0   24    Jane
1   21    John
2   26    Matt
3   32  Ashley
#=================

print(df.shape)

#=====Output====== two columns and four rows
(4, 2)
#=================
```

## 2. DataFrame

### Reading Data from a File

The pandas `read_csv` function creates a `DataFrame` from a csv file. Pandas provides several other functions for reading data in files with different formats, such as `read_json`, `read_parquet`, `read_excel`, and so on.

```python
import pandas as pd

sales = pd.read_csv("sales.csv")
print(sales.head())
```

**Output**

[![pSuhneO.png](https://s1.ax1x.com/2023/01/12/pSuhneO.png)](https://imgse.com/i/pSuhneO)

### Using `usecols` parameter

There are several other parameters of the `read_csv`function. For instance, we have the option to read only some of the columns from the csv file.

```python
import pandas as pd

sales = pd.read_csv("sales.csv", usecols=["product_code","product_group","stock_qty"])

print(sales.head())
```

**Output**[![pSuhJ6P.png](https://s1.ax1x.com/2023/01/12/pSuhJ6P.png)](https://imgse.com/i/pSuhJ6P)

DataFrame ç”±è¡Œå’Œåˆ—ç»„æˆã€‚å°±åƒæˆ‘ä»¬å¯ä»¥é€‰æ‹©åªè¯»å–éƒ¨åˆ†åˆ—ä¸€æ ·ï¼Œread_csv å‡½æ•°è®©æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ nrows å‚æ•°é™åˆ¶è¯»å–çš„è¡Œæ•°ã€‚è¿™åœ¨å¤„ç†å¤§æ–‡ä»¶æ—¶ç‰¹åˆ«æœ‰ç”¨ã€‚

### Create a DataFrame

#### Python dictionary

æœ€å¸¸ç”¨çš„æ–¹æ³•ä¹‹ä¸€æ˜¯ç”¨Pythonå­—å…¸æ¥åšåˆ°è¿™ä¸€ç‚¹ã€‚

```python
import pandas as pd

df = pd.DataFrame({
  "Names": ["Jane", "John", "Matt", "Ashley"],
  "Ages": [26, 24, 28, 25],
  "Score": [91.2, 94.1, 89.5, 92.3]
})

print(df)
```

**Output**[![pSuhrpn.png](https://s1.ax1x.com/2023/01/12/pSuhrpn.png)](https://imgse.com/i/pSuhrpn)

#### Two-dimensional array

DataFrameæ˜¯ä¸€ç§äºŒç»´æ•°æ®ç»“æ„ï¼Œç”±è¡Œå’Œåˆ—ç»„æˆã€‚å› æ­¤ï¼Œæˆ‘ä»¬å¯ä»¥å°†ä¸€ä¸ªäºŒç»´æ•°ç»„è½¬æ¢æˆDataFrameã€‚ä¾‹å¦‚ï¼ŒDataFrameæ„é€ å‡½æ•°æ¥å—NumPyæ•°ç»„ã€‚

ä¸‹é¢çš„ä»£ç ç”¨ä¸€ä¸ªNumPyæ•°ç»„åˆ›å»ºäº†ä¸€ä¸ªDataFrameã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ—åè¢«åˆ†é…æ•´æ•°ç´¢å¼•ï¼Œä½†æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åˆ—å‚æ•°æ¥æ”¹å˜å®ƒã€‚

`randint` æ˜¯ç”Ÿæˆ1ï¼Œ10çš„éšæœºæ•°

```python
import numpy as np
import pandas as pd

arr = np.random.randint(1, 10, size=(3,5))

df = pd.DataFrame(arr, columns=["A","B","C","D","E"])

print(df)
```

**Output**

[![pSuh6XV.png](https://s1.ax1x.com/2023/01/12/pSuh6XV.png)](https://imgse.com/i/pSuh6XV)

### Size of a DataFrame

The `size`, `shape`, and `len` methods

shapeæ–¹æ³•è¿”å›ä¸€ä¸ªåŒ…å«è¡Œæ•°å’Œåˆ—æ•°çš„å…ƒç»„ã€‚sizeæ–¹æ³•åŒ…å«ä¸€ä¸ªæ•°å­—ï¼Œæ˜¾ç¤ºè¡Œçš„æ•°é‡ä¹˜ä»¥åˆ—çš„æ•°é‡ã€‚å› æ­¤ï¼Œå®ƒè¿”å› DataFrame ä¸­å•å…ƒæ ¼çš„æ€»æ•°ã€‚å†…ç½®çš„ Python å‡½æ•° len ç»™æˆ‘ä»¬æä¾›äº† DataFrame ä¸­çš„è¡Œæ•°ã€‚è®©æˆ‘ä»¬ç”¨è¿™äº›æ–¹æ³•æ¥æ£€æŸ¥é”€å”®çš„å¤§å°ã€‚
ä¸‹é¢çš„ä»£ç ç”¨ä¸€ä¸ªNumPyæ•°ç»„åˆ›å»ºäº†ä¸€ä¸ªDataFrameã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œåˆ—åè¢«åˆ†é…æ•´æ•°ç´¢å¼•ï¼Œä½†æˆ‘ä»¬å¯ä»¥ä½¿ç”¨åˆ—å‚æ•°æ¥æ”¹å˜å®ƒã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print(sales.shape)

print(sales.size)

print(len(sales))
```

[![pSuhvhd.png](https://s1.ax1x.com/2023/01/12/pSuhvhd.png)](https://imgse.com/i/pSuhvhd)

### Data Types of Columns

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print(sales.dtypes)


print("As index:")
print(sales.columns)

print("As list:")
print(list(sales.columns))
```

[![pSuTUiD.png](https://s1.ax1x.com/2023/01/12/pSuTUiD.png)](https://imgse.com/i/pSuTUiD)

[![pSuTdRH.png](https://s1.ax1x.com/2023/01/12/pSuTdRH.png)](https://imgse.com/i/pSuTdRH)

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨astpyeå‡½æ•°æ¥æ”¹å˜åˆ—çš„æ•°æ®ç±»å‹ã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

sales["stock_qty"] = sales["stock_qty"].astype("float")

print(sales.dtypes)
```

[![pSuT2FS.png](https://s1.ax1x.com/2023/01/12/pSuT2FS.png)](https://imgse.com/i/pSuT2FS)

The `astype` function also accepts a dictionary, so we can change the data type of multiple columns in a single operation. The dictionary keys indicate that the column name and values are the new data types.

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

sales = sales.astype({
  "stock_qty": "float",
  "last_week_sales": "float"
})

print(sales.dtypes)
```

[![pSuTWWQ.png](https://s1.ax1x.com/2023/01/12/pSuTWWQ.png)](https://imgse.com/i/pSuTWWQ)

### Different Values in a Column

#### Using the `unique` and `nunique` functions

DataFrameä¸­çš„åˆ—å¯èƒ½æ˜¯åˆ†ç±»çš„æˆ–è¿ç»­çš„ã€‚åˆ†ç±»åˆ—å¯èƒ½æœ‰è®¸å¤šä¸åŒä½†æœ‰é™çš„å€¼ï¼Œè€Œè¿ç»­åˆ—å¯ä»¥æœ‰æ— é™å¤šçš„å€¼ã€‚åœ¨è¿™ä¸ªæ„ä¹‰ä¸Šï¼Œè¿™äº›åˆ—å¯ä»¥è¢«è§†ä¸ºç¦»æ•£çš„æˆ–åˆ†ç±»çš„éšæœºå˜é‡ã€‚

æ£€æŸ¥åˆ†ç±»åˆ—ä¸­çš„ç‹¬ç‰¹å€¼çš„æ•°é‡æ˜¯æ¢ç´¢æ€§æ•°æ®åˆ†æçš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†ã€‚nuniqueå‡½æ•°è¿”å›ä¸€åˆ—ä¸­ç‹¬ç‰¹å€¼çš„æ•°é‡ï¼Œuniqueå‡½æ•°å®é™…ä¸Šæ˜¾ç¤ºäº†ç‹¬ç‰¹å€¼ã€‚æˆ‘ä»¬å¯ä»¥å°†å®ƒä»¬åº”ç”¨äºé”€å”®ä¸­çš„äº§å“ç»„åˆ—ã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print(sales["product_group"].nunique())
#6
print(sales["product_group"].unique())
# ['PG2' 'PG4' 'PG6' 'PG5' 'PG3' 'PG1']
```

#### The `value_counts` function

æœ‰å…­ä¸ªä¸åŒçš„äº§å“ç»„ã€‚æˆ‘ä»¬å¯èƒ½è¿˜éœ€è¦æ£€æŸ¥æ¯ä¸ªäº§å“ç»„æœ‰å¤šå°‘è¡Œã€‚value_countså‡½æ•°è¿”å›ä¸€åˆ—ä¸­æ‰€æœ‰ä¸åŒçš„å€¼ï¼Œä»¥åŠå®ƒä»¬å‡ºç°çš„æ¬¡æ•°ã€‚

value_countså‡½æ•°æ˜¯æœ€ç»å¸¸ä½¿ç”¨çš„Pandaså‡½æ•°ä¹‹ä¸€ï¼Œå› ä¸ºå®ƒæä¾›äº†ä¸€ä¸ªå¿«é€Ÿæ¢ç´¢åˆ†ç±»åˆ—çš„æ–¹æ³•ã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print(sales["product_group"].value_counts())
```

```makefile
Output

PG4    349
PG5    255
PG6    243
PG2     75
PG1     39
PG3     39
Name: product_group, dtype: int64
```

### Measures of Central Tendency

#### The meanå¹³å‡æ•°, medianä¸­ä½æ•°, and mode

- å¹³å‡å€¼æ˜¯æŒ‡å¹³å‡æ•°å€¼ã€‚å®ƒå¯ä»¥é€šè¿‡å°†æ•°æ®é›†ä¸­çš„æ‰€æœ‰æ•°å­—ç›¸åŠ ï¼Œç„¶åå°†æ€»å’Œé™¤ä»¥æ•°å€¼çš„æ•°é‡æ¥è®¡ç®—ã€‚
- ä¸­ä½æ•°æ˜¯æ•°å€¼æŒ‰å‡åºæˆ–é™åºæ’åºæ—¶çš„ä¸­é—´å€¼ã€‚å¦‚æœæ•°æ®é›†ä¸­çš„æ•°å€¼æ•°é‡æ˜¯å¶æ•°ï¼Œä¸­ä½æ•°å°±æ˜¯ä¸­é—´ä¸¤ä¸ªæ•°å€¼çš„å¹³å‡å€¼

```python
import pandas as pd

myseries = pd.Series([1, 2, 5, 7, 11, 36])
print(myseries.median())
#output
6.0

print(f"The mode of my series is {myseries.mode()[0]}")
#output
The mode of my series is 6

```

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print("mean: ")
print(sales["price"].mean())

print("median: ")
print(sales["price"].median())

print("mode: ")
print(sales["price"].mode()[0])

print("minimum: ")
print(sales["price"].min())

print("maximum: ")
print(sales["price"].max())

#output
mean: 
67.06351000000001
median: 
23.74
mode: 
10.44
minimum: 
0.66
maximum: 
```

å¹³å‡ä»·æ ¼çº¦ä¸º 67ï¼Œä¸­ä½æ•°çº¦ä¸º 23ã€‚è¿™è¡¨æ˜æˆ‘ä»¬æœ‰ä¸€äº›äº§å“çš„ä»·æ ¼æ¯”å…¶ä»–äº§å“é«˜ã€‚

é›†ä¸­è¶‹åŠ¿çš„åº¦é‡æ˜¯æè¿°æ€§ç»Ÿè®¡çš„åŸºç¡€ã€‚ä¸ºäº†æ›´å¥½åœ°ç†è§£å˜é‡çš„åˆ†å¸ƒï¼Œæˆ‘ä»¬è¿˜éœ€è¦è€ƒè™‘æ–¹å·®æˆ–æ ‡å‡†å·®ã€‚

æ–¹å·®æ˜¯å€¼ä¹‹é—´å·®å¼‚çš„åº¦é‡ã€‚å¯ä»¥è®¡ç®—å¦‚ä¸‹ï¼š

1. æ‰¾å‡ºæ•°æ®é›†ä¸­æ¯ä¸ªå€¼ä¸å¹³å‡å€¼ä¹‹é—´çš„å·®å¼‚ã€‚
2. å–å·®çš„å¹³æ–¹ã€‚
3. æ±‚å¹³æ–¹å·®çš„å¹³å‡å€¼ã€‚

æ ‡å‡†åå·®æ˜¯è¡¡é‡å€¼åˆ†æ•£ç¨‹åº¦çš„æŒ‡æ ‡ã€‚æ›´å…·ä½“åœ°è¯´ï¼Œå®ƒæ˜¯æ–¹å·®çš„å¹³æ–¹æ ¹ã€‚

Pandasçš„`var`å’Œ`std`æ–¹æ³•å¯ä»¥åˆ†åˆ«è®¡ç®—æ–¹å·®å’Œæ ‡å‡†å·®ã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print("variance: ")
print(sales["price"].var())

print("standard deviation: ")
print(sales["price"].std())
```

```python
# Output
variance: 
20766.243824604506
standard deviation: 
144.10497501684148
```

æ–¹å·®å’Œæ ‡å‡†å·®è®©æˆ‘ä»¬äº†è§£åˆ°æ•°å€¼æ˜¯å¦‚ä½•å›´ç»•ä¸­å¿ƒè¶‹åŠ¿çš„è¡¡é‡æ ‡å‡†åˆ†å¸ƒçš„ã€‚ä¸€èˆ¬æ¥è¯´ï¼Œæ ‡å‡†å·®è¶Šå¤§ï¼Œæ•°å€¼å°±è¶Šåˆ†æ•£ã€‚

### ç»ƒä¹ ï¼šFind the Most Frequent Values in a Column

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

def find_most_frequents(column_name):
  try:
    # print(sales[column_name].value_counts())
    return list(sales[column_name].value_counts().index[0:3])
  except:
    pass

```

#### Python indexå‡½æ•°

index() å‡½æ•°ç”¨äºä»åºåˆ—sä¸­æ‰¾å‡ºæŸä¸ªå€¼ç¬¬ä¸€ä¸ªå‡ºç°æ—¶çš„ç´¢å¼•ä½ç½®ã€‚

```python
list.index(x[, start[, end]])
```

- x-- æŸ¥æ‰¾çš„å¯¹è±¡ã€‚
- start-- å¯é€‰ï¼ŒæŸ¥æ‰¾çš„èµ·å§‹ä½ç½®ã€‚
- end-- å¯é€‰ï¼ŒæŸ¥æ‰¾çš„ç»“æŸä½ç½®ã€‚



## 3. Filtering DataFrame

- å½“æˆ‘ä»¬éœ€è¦ä¸ºæŸäº›ä»»åŠ¡åˆ é™¤å†—ä½™æˆ–ä¸å¿…è¦çš„æ•°æ®æ—¶ï¼Œæˆ‘ä»¬ä¼šè¿›è¡Œè¿‡æ»¤ã€‚å‡è®¾æˆ‘ä»¬æ­£åœ¨å¤„ç†ä¸€é¡¹é¢„æµ‹å®¢æˆ·æµå¤±çš„æœºå™¨å­¦ä¹ ä»»åŠ¡ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®¢æˆ·çš„é“¶è¡Œå¸å·æ˜¯å¤šä½™çš„ï¼Œéœ€è¦è¿‡æ»¤æ‰ã€‚
- è€ƒè™‘åœ¨é“¶è¡Œå·¥ä½œçš„æ•°æ®åˆ†æå¸ˆã€‚è¯¥é“¶è¡Œè®¡åˆ’é’ˆå¯¹åœ¨è´¦æˆ·ä½™é¢ã€æ¯æœˆæ”¯å‡ºå’Œäº§å“ï¼ˆæ‹¥æœ‰ä¿¡ç”¨å¡æˆ–æ”¯ç¥¨è´¦æˆ·ï¼‰æ–¹é¢æ»¡è¶³ç‰¹å®šæ ‡å‡†çš„å®¢æˆ·å®£å¸ƒä¸€é¡¹ä¿ƒé”€æ´»åŠ¨ã€‚æ•°æ®åˆ†æå¸ˆéœ€è¦è¿‡æ»¤æ•°æ®ä»¥æ‰¾åˆ°ç¬¦åˆä¿ƒé”€æ¡ä»¶çš„å®¢æˆ·ã€‚
- æ•°æ®æ¸…ç†å’Œæ“ä½œä¹Ÿéœ€è¦è¿‡æ»¤ã€‚æˆ‘ä»¬å¯èƒ½å¸Œæœ›è¿‡æ»¤æ‰`DataFrame`æŸäº›åˆ—ä¸­ç¼ºå¤±å€¼çš„è§‚å¯Ÿå€¼ï¼ˆa ä¸­çš„è¡Œï¼‰ã€‚
- è¿‡æ»¤ä¹Ÿç»å¸¸ç”¨äºæ•°æ®åˆ†æã€‚å‡è®¾æˆ‘ä»¬æ ¹æ®æ¶ˆè´¹é‡‘é¢å¯¹å®¢æˆ·è¿›è¡Œåˆ†ç»„ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬ä¼šæ ¹æ®èŠ±è´¹çš„é‡‘é¢ç­›é€‰å®¢æˆ·ï¼Œç„¶åå¯¹ä»–ä»¬è¿›è¡Œåˆ†ç»„ã€‚

### â€œlocâ€å’Œâ€œilocâ€

`loc`å’Œ`iloc`æ–¹æ³•æ˜¯ç”¨äºè¿‡æ»¤ã€é€‰æ‹©å’Œæ“ä½œæ•°æ®çš„åŸºæœ¬ Pandas æ–¹æ³•ã€‚å®ƒä»¬å…è®¸æˆ‘ä»¬è®¿é—®æ‰€éœ€çš„è¡Œå’Œåˆ—ç»„åˆã€‚

- `loc`ä½¿ç”¨è¡Œå’Œåˆ—æ ‡ç­¾ã€‚
- `iloc`ä½¿ç”¨è¡Œå’Œåˆ—ç´¢å¼•ã€‚



[![pSKicGj.png](https://s1.ax1x.com/2023/01/13/pSKicGj.png)](https://imgse.com/i/pSKicGj)

ç”¨locæ–¹æ³•æ¥é€‰æ‹©é”€å”®ä¸­çš„å‰äº”è¡Œ( :4  )å’Œä¸¤åˆ—ã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print(sales.loc[:4, ["product_code","product_group"]])
```

[![pSKi2zn.png](https://s1.ax1x.com/2023/01/13/pSKi2zn.png)](https://imgse.com/i/pSKi2zn)

:4ç›¸å½“äº0:4ï¼Œå®ƒè¡¨ç¤ºä»0åˆ°4å¼€å§‹çš„è¡Œæ•°ã€‚åˆ—åä»¥åˆ—è¡¨å½¢å¼ä¼ é€’ç»™locæ–¹æ³•ã€‚è®©æˆ‘ä»¬ç”¨ilocæ–¹æ³•åšåŒæ ·çš„æ“ä½œã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

print(sales.iloc[[5,6,7,8], [0,1]])

print(sales.iloc[5:9, :2])
```

[![pSKiIdU.png](https://s1.ax1x.com/2023/01/13/pSKiIdU.png)](https://imgse.com/i/pSKiIdU)

ä¸¤ä¸ªä»£ç åšåŒæ ·çš„äº‹æƒ…ã€‚5:9 æ¯”åœ¨åˆ—è¡¨ä¸­ä»¥[5,6,7,8]çš„å½¢å¼ä¼ é€’ç´¢å¼•æ›´æ–¹ä¾¿ã€‚

`iloc`ä¸»è¦åŒºåˆ«åœ¨äºå®ƒ`loc`é€‚ç”¨äºæ ‡ç­¾ï¼Œè€Œ`iloc`é€‚ç”¨äºç´¢å¼•

```python
import numpy as np
import pandas as pd

df = pd.DataFrame(
  np.random.randint(10, size=(4,4)),
  index = ["a","b","c","d"],
  columns = ["col_a","col_b","col_c","col_d"]
  )

print(df)

print("\nSelect two rows and two columns using loc:")
print(df.loc[["b","d"], ["col_a","col_c"]])
```

```
   col_a  col_b  col_c  col_d
a      0      7      7      4
b      4      3      4      9
c      5      1      0      2
d      3      0      9      9


Select two rows and two columns using loc:
   col_a  col_c
b      4      4
d      3      9
```

locå’Œilocæ–¹æ³•ç»å¸¸è¢«ç”¨æ¥é€‰æ‹©æˆ–æå–æ•°æ®æ¡†æ¶çš„ä¸€éƒ¨åˆ†ã€‚ä¸»è¦çš„åŒºåˆ«æ˜¯ï¼Œlocä½¿ç”¨çš„æ˜¯æ ‡ç­¾ï¼Œè€Œilocä½¿ç”¨çš„æ˜¯ç´¢å¼•ã€‚

### è¿‡æ»¤columnså­é›†

[![pSKizdO.png](https://s1.ax1x.com/2023/01/13/pSKizdO.png)](https://imgse.com/i/pSKizdO)

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

selected_columns = ["product_code","price"]

print(sales[selected_columns].head())


#æˆ‘ä»¬ä¸éœ€è¦åˆ›å»ºä¸€ä¸ªåŒ…å«åˆ—åçš„åˆ—è¡¨ã€‚åŒæ ·çš„æ“ä½œä¹Ÿå¯ä»¥é€šè¿‡è¿™ä¸€è¡Œæ¥å¤„ç†ã€‚
print(sales["product_code","price"].head())
```

```
   product_code    price
0          4187   569.91
1          4195   712.41
2          4204   854.91
3          4219  1034.55
4          4718    26.59
```

### æ¡ä»¶è¿‡æ»¤

```python
sales_filtered = sales[sales.product_group == "PG2"]
sales_filtered = sales[sales["product_group"] == "PG2"]
#ç­‰ä»·
```

```python
#é€‰æ‹©ä»·æ ¼é«˜äº 100 çš„äº§å“ã€‚
sales_filtered = sales[sales["price"] > 100]
```

- `==`ï¼š å¹³ç­‰çš„
- `!=`: ä¸ç›¸ç­‰
- `>`ï¼š æ¯”...æ›´æ£’
- `>=`: å¤§äºæˆ–ç­‰äº
- `<`ï¼š å°‘äº
- `<=`: å°äºæˆ–ç­‰äº

#### å¤šæ¡ä»¶

é€‰æ‹©ä»·æ ¼å¤§äº100ï¼Œåº“å­˜æ•°é‡å°äº400çš„å•†å“ï¼Œæˆ‘ä»¬åªéœ€è¦å°†è¿™äº›æ¡ä»¶å’Œ`&`ç®—å­ç»“åˆèµ·æ¥å°±å¯ä»¥äº†ã€‚

```python
import pandas as pd

# read the sales csv file
sales = pd.read_csv("sales.csv")

# filter the sales data frame
sales_filtered = sales[(sales["price"] > 100) & (sales["stock_qty"] < 400)]

print(sales_filtered[["price","stock_qty"]].head())
```

|è¿ç®—ç¬¦ç”¨äºç”¨ORé€»è¾‘ç»“åˆå¤šä¸ªæ¡ä»¶ã€‚ä¾‹å¦‚ï¼Œä¸‹é¢ä¸€è¡Œä»£ç é€‰æ‹©å±äºPG1æˆ–PG2äº§å“ç»„çš„äº§å“ã€‚

```python
sales_filtered = sales[(sales["product_group"] == "PG1") | (sales["product_group"] == "PG2")]
```

#### `isin` æ–¹æ³•

è€ƒè™‘è¿™æ ·ä¸€ç§æƒ…å†µï¼Œæˆ‘ä»¬è¦é€‰æ‹©å±äºä¸‰ä¸ªä¸åŒç±»åˆ«ä¹‹ä¸€çš„äº§å“ã€‚ä¸€ç§é€‰æ‹©æ˜¯ç¼–å†™ä¸‰ä¸ªä¸åŒçš„è¿‡æ»¤å™¨å¹¶å°†å®ƒä»¬ä¸`|`è¿ç®—ç¬¦ç»„åˆã€‚

```python
sales_filtered = sales[sales["product_group"].isin(["PG1","PG2","PG3"])]
```

æœ€åï¼Œæˆ‘ä»¬æœ‰éè¿ç®—ç¬¦ ( `~`)ã€‚`DataFrame`å®ƒç”¨åœ¨æ–¹æ‹¬å·å†…çš„åç§°ä¹‹å‰ã€‚

æˆ‘ä»¬å¯ä»¥é€‰æ‹©ä¸åœ¨äº§å“ç»„`PG1`ã€`PG2`æˆ–ä¸­çš„äº§å“ï¼Œ`PG3`å¦‚ä¸‹æ‰€ç¤ºï¼š

```python
sales_filtered = sales[~sales["product_group"].isin(["PG1","PG2","PG3"])]
```

`not`å½“æˆ‘ä»¬æƒ³ä»ä¸€ç»„å¤šä¸ªå€¼ä¸­æ’é™¤å‡ ä¸ªå€¼æ—¶ï¼Œè¯¥è¿ç®—ç¬¦å¾ˆæœ‰ç”¨ã€‚

### ä½¿ç”¨æŸ¥è¯¢å‡½æ•°è¿‡æ»¤è¡Œ

#### Query

`query`å‡½æ•°æ˜¯å¦ä¸€ç§è¿‡æ»¤`DataFrame`.

é€‰æ‹©ä»·æ ¼é«˜äº 100 çš„äº§å“`query`ï¼š

```python
sales_filtered = sales.query("price > 100")
```

æˆ‘ä»¬åˆ›å»ºäº†ä¸€ä¸ªåŸºäºä»·æ ¼å’Œåº“å­˜æ•°é‡åˆ—çš„æ¡ä»¶ã€‚

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

sales_filtered = sales.query("price > 100 and stock_qty < 400")

print(sales_filtered[["product_code","price","stock_qty"]].head())
```

```
     product_code    price  stock_qty
3            4219  1034.55        241
8            2650   111.06        239
165          1657   208.91        244
186          7269   427.41        369
199          3530   104.49        144
```

åœ¨å†™ä¸€ä¸ªå®é™…æ¶‰åŠåˆ°å­—ç¬¦ä¸²çš„æ¡ä»¶æ—¶ï¼Œæˆ‘ä»¬éœ€è¦ç‰¹åˆ«å°å¿ƒã€‚

```python
sales_filtered = sales.query("product_group == 'PG2'")
```

### ç»ƒä¹  Filter Out the Values Below Average

```python
import pandas as pd

sales = pd.read_csv("sales.csv")

def find_the_number_of_products():
  try:
    """
    average_price = # find the mean value of the price column
    sales_filtered = # filter the products that have a price higher than the average price
    number_of_products = # find the number of unique product codes in sales_filtered
    """
    average_price = sales["price"].median()
    sales_filtered = sales[sales["price"] > average_price]
    number_of_products = sales_filtered["product_code"].unique()
    return number_of_products
  except:
    pass
```

## 4. String å­—ç¬¦ä¸²æ“ä½œ

æ–‡æœ¬æ•°æ®æ˜¯æ•°æ®ç§‘å­¦çš„é‡è¦ç»„æˆéƒ¨åˆ†ã€‚æœ‰äº›é¢†åŸŸéœ€è¦è¿‡åº¦å¤„ç†æ–‡æœ¬æ•°æ®ï¼Œä¾‹å¦‚è‡ªç„¶è¯­è¨€å¤„ç† (NLP)ã€‚Pandas åº“æä¾›äº†å¤šç§å¤„ç†æ–‡æœ¬æ•°æ®çš„å‡½æ•°å’Œæ–¹æ³•ã€‚å®ƒä»¬å¯ä»¥é€šè¿‡è®¿é—®å™¨è®¿é—®`str`

**staff.csv**

| **name**             | **city**        | **date_of_birth** | **start_date** | **salary** | **department**  |
| -------------------- | --------------- | ----------------- | -------------- | ---------- | --------------- |
| **John Doe**         | Houston, TX     | 1998-11-04        | 2018-08-11     | $65,000    | Accounting      |
| **Jane Doe**         | San Jose, CA    | 1995-08-05        | 2017-08-24     | $70,000    | Field Quality   |
| **Matt smith**       | Dallas, TX      | 1996-11-25        | 2020-04-16     | $58,500    | human resources |
| **Ashley Harris**    | Miami, FL       | 1995-01-08        | 2021-02-11     | $49,500    | accounting      |
| **Jonathan targett** | Santa Clara, CA | 1998-08-14        | 2020-09-01     | $62,000    | field quality   |
| **Hale Cole**        | Atlanta, GA     | 2000-10-24        | 2021-10-20     | $54,500    | engineering     |

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(f"\nStaff data frame has the following columns: \n{list(staff.columns)}\n")

print(staff)
```

[![pSKFjpj.png](https://s1.ax1x.com/2023/01/13/pSKFjpj.png)](https://imgse.com/i/pSKFjpj)

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["name"].str[0])
```

```
0    J
1    J
2    M
3    A
4    J
5    H
Name: name, dtype: object
```

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["name"].str[0:3])
```

```
0    Joh
1    Jan
2    Mat
3    Ash
4    Jon
5    Hal
Name: name, dtype: object
```

å¦‚æœæƒ³è¦çš„ç‰‡æ–­ä»ç¬¬ä¸€ä¸ªç´¢å¼•ï¼ˆ0ï¼‰å¼€å§‹ï¼Œæˆ‘ä»¬å°±ä¸éœ€è¦å†™åˆå§‹ç´¢å¼•ã€‚å› æ­¤ï¼Œä¸‹é¢è¿™è¡Œä»£ç çš„ä½œç”¨ä¸ä¸Šè¿°ç›¸åŒã€‚

```python
staff["name"].str[:3]
```

å€¼å¾—æ³¨æ„çš„æ˜¯ï¼Œä¸Šç•Œæ˜¯æ’ä»–æ€§çš„ã€‚å› æ­¤ï¼Œ[:3]è¡¨ç¤ºç´¢å¼•0ã€1å’Œ2ã€‚ä¹Ÿå¯ä»¥ä½¿ç”¨ä»å­—ç¬¦ä¸²æœ«ç«¯å¼€å§‹çš„ç´¢å¼•ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç´¢å¼•ä»-1å¼€å§‹ï¼Œç»§ç»­ä¸º-2ã€-3ï¼Œä»¥æ­¤ç±»æ¨ã€‚ä¸‹é¢è¿™è¡Œä»£ç è¿”å›åŸå¸‚åˆ—çš„æœ€åä¸¤ä¸ªå­—ç¬¦ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["name"].str[-2:])
```

```
0    oe
1    oe
2    th
3    is
4    tt
5    le
Name: name, dtype: object
```

ä¸ºäº†ä½¿åˆ‡ç‰‡å’Œç´¢å¼•æ“ä½œæ›´åŠ çµæ´»ï¼ŒPandasä¹Ÿå…è®¸è‡ªå®šä¹‰æ­¥éª¤å¤§å°ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åˆ›å»ºä¸€ä¸ªæ¶‰åŠæ¯ä¸€ä¸ªå…¶ä»–å­—ç¬¦çš„åˆ‡ç‰‡ï¼Œä»å€’æ•°ç¬¬äºŒçš„ç´¢å¼•å¼€å§‹ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["name"].str[1::2])
```

```
0        onDe
1        aeDe
2       atsih
3      slyHri
4    oahntret
5        aeCl
Name: name, dtype: object
```

**æ ¼å¼**

```python
str[start : end : step size]
```

å¦‚æœç»“å°¾å¤„ç•™æœ‰ç©ºç™½ï¼Œé‚£ä¹ˆåˆ†ç‰‡å°±ä¼šä¸Šå‡åˆ°å­—ç¬¦ä¸²çš„æœ«ç«¯ã€‚

### åˆ†å‰²å’Œç»„åˆ Strings

#### Splitting

åœ¨Staffä¸­ï¼Œå§“ååˆ—åŒ…å«äº†åå­—å’Œå§“æ°ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡ä½¿ç”¨åˆ†å‰²å‡½æ•°å¾ˆå®¹æ˜“åœ°ä»å§“ååˆ—ä¸­æå–å§“æˆ–åã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["name"].str.split(" "))
```

```
0            [John, Doe]
1            [Jane, Doe]
2          [Matt, smith]
3       [Ashley, Harris]
4    [Jonathan, targett]
5           [Hale, Cole]
Name: name, dtype: object
```

ä»…ä»…åˆ†å‰²ä¸€ä¸ªå­—ç¬¦ä¸²æ˜¯ä¸å¤Ÿçš„ã€‚æˆ‘ä»¬è¿˜éœ€è¦æå–æˆ‘ä»¬éœ€è¦çš„éƒ¨åˆ†ã€‚

splitå‡½æ•°çš„expandå‚æ•°å¯ç”¨æ¥åœ¨åˆ†å‰²ååˆ›å»ºç‹¬ç«‹çš„åˆ—ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

staff["last_name"] = staff["name"].str.split(" ", expand=True)[1]

print(staff[["name","last_name"]])
```

```
               name last_name
0          John Doe       Doe
1          Jane Doe       Doe
2        Matt smith     smith
3     Ashley Harris    Harris
4  Jonathan targett   targett
5         Hale Cole      Cole
```

#### Combining

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["name"] + " - " + staff["department"])
```

```
0               John Doe - Accounting
1            Jane Doe - Field Quality
2        Matt smith - human resources
3          Ashley Harris - accounting
4    Jonathan targett - field quality
5             Hale Cole - engineering
dtype: object
```

è¿™äº›æ“ä½œç»å¸¸è¢«ä½¿ç”¨ï¼Œå› ä¸ºå­—ç¬¦ä¸²æˆ–æ–‡æœ¬æ•°æ®å¯èƒ½åŒ…å«å¤šä¸ªä¿¡æ¯ç‰‡æ®µã€‚

### å¤§å°å†™è½¬æ¢ Strings

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

staff["name_lower"] = staff["name"].str.lower()

print(staff[["name","name_lower"]])
```

```
               name        name_lower
0          John Doe          john doe
1          Jane Doe          jane doe
2        Matt smith        matt smith
3     Ashley Harris     ashley harris
4  Jonathan targett  jonathan targett
5         Hale Cole         hale cole
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨çš„å¦ä¸€ä¸ªå‡½æ•°æ˜¯ `capitalize`å‡½æ•°ã€‚å®ƒåªå°†ç¬¬ä¸€ä¸ªå­—æ¯è½¬æ¢ä¸ºå¤§å†™ã€‚è®©æˆ‘ä»¬ç”¨å®ƒæ¥å°†`department` åˆ—ä¸­çš„æ•°å€¼å¤§å†™ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["department"].str.capitalize())
```

```
0         Accounting
1      Field quality
2    Human resources
3         Accounting
4      Field quality
5        Engineering
Name: department, dtype: object
```

é™¤äº†å°†ç¬¬ä¸€ä¸ªå­—æ¯è½¬æ¢ä¸ºå¤§å†™å¤–ï¼Œå¤§å†™å‡½æ•°è¿˜ç¡®ä¿æ‰€æœ‰å…¶ä»–å­—æ¯éƒ½æ˜¯å°å†™ã€‚å› æ­¤ï¼Œå¦‚æœé™¤äº†ç¬¬ä¸€ä¸ªå­—æ¯ä¹‹å¤–è¿˜æœ‰ä¸€ä¸ªå¤§å†™å­—æ¯ï¼Œå®ƒå°±ä¼šè¢«è½¬æ¢ä¸ºå°å†™ã€‚

```python
import pandas as pd

sales = pd.read_csv("staff.csv")

print(sales["department"][0].upper())
```

```
ACCOUNTING
```

#### ç»ƒä¹ Create City and State Columns from the Address

[![pSKkkh4.png](https://s1.ax1x.com/2023/01/13/pSKkkh4.png)](https://imgse.com/i/pSKkkh4)

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

def create_city_column():
  try:
    staff["state"] = staff["city"].str.split(",", expand=True)[1]
    return list(staff["state"])
 
  except:
    pass
```

### æ›¿æ¢å­—ç¬¦ in a String

Pandasåº“æä¾›äº†é«˜åº¦çµæ´»çš„æ–¹æ³•æ¥å¤„ç†å­—ç¬¦ä¸²ã€‚å…¶ä¸­ä¹‹ä¸€æ˜¯`str`è®¿é—®å™¨ä¸‹çš„æ›¿æ¢å‡½æ•°ã€‚å®ƒå¯ä»¥ç”¨æ¥æ›¿æ¢å­—ç¬¦ä¸²ä¸­çš„ä¸€ä¸ªå­—ç¬¦æˆ–ä¸€ä¸ªå­—ç¬¦åºåˆ—ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["city"].str.replace(",", "-"))
```

```
0        Houston- TX
1       San Jose- CA
2         Dallas- TX
3          Miami- FL
4    Santa Clara- CA
5        Atlanta- GA
Name: city, dtype: object
```

åœ¨å‰é¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†strè®¿é—®å™¨ä¸‹çš„æ›¿æ¢å‡½æ•°ã€‚Pandasåº“è¿˜æä¾›äº†DataFrame.replaceå‡½æ•°ï¼Œå¯ä»¥ç”¨æ¥æ›¿æ¢æ•´ä¸ªå€¼ã€‚è®©æˆ‘ä»¬ä¹Ÿæ¥çœ‹çœ‹è¿™ä¸ªæ›¿æ¢å‡½æ•°çš„ä¾‹å­ã€‚æˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºä¸€ä¸ªçŠ¶æ€åˆ—ï¼Œç„¶åç”¨å®é™…çš„çŠ¶æ€åç§°æ›¿æ¢ç¼©å†™ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

# Create a state colum
staff["state"] = staff["city"].str[-2:]

# Replace state abbreviations with actual state names
staff["state"].replace(
    {"TX": "Texas", "CA": "California", "FL": "Florida", "GA": "Georgia"},
    inplace = True
)

print(staff["state"])
```

```
0         Texas
1    California
2         Texas
3       Florida
4    California
5       Georgia
Name: state, dtype: object
```

å‚æ•°`inplace`è¢«è®¾ç½®ä¸º `True` ï¼Œä»¥ä¿å­˜åœ¨ `DataFrame`ä¸­çš„å˜åŒ–ã€‚

- `str.replace`å¯ä»¥ç”¨æ¥æ›¿æ¢ä¸€ä¸ªå­—ç¬¦ä¸²çš„ä¸€éƒ¨åˆ†ã€‚æˆ‘ä»¬å¯ä»¥æ›¿æ¢ä¸€ä¸ªå­—ç¬¦ï¼Œå¤šä¸ªå­—ç¬¦ï¼Œæˆ–è€…æ•´ä¸ªå­—ç¬¦ä¸²ã€‚
- `DataFrame.replace`å¯ä»¥ç”¨æ¥æ›¿æ¢æ•´ä¸ªå€¼ã€‚æˆ‘ä»¬ä¹Ÿå¯ä»¥ç”¨è¿™ä¸ªå‡½æ•°æ¥æ›¿æ¢å…¶ä»–æ•°æ®ç±»å‹çš„å€¼ï¼Œå¦‚æ•´æ•°å’Œå¸ƒå°”å€¼ã€‚

### é“¾å¼æ“ä½œChained Operations

æˆ‘ä»¬éœ€è¦åº”ç”¨ä¸€ç³»åˆ—çš„æ“ä½œæ¥å®Œæˆæ‰€éœ€çš„ä»»åŠ¡ã€‚æˆ‘ä»¬å¯ä»¥åœ¨ä¸€ä¸ªå•ç‹¬çš„è¡Œæˆ–æ­¥éª¤ä¸­å®Œæˆæ¯ä¸ªä»»åŠ¡ã€‚ç„¶è€Œï¼ŒPandasåº“ä¸ºæˆ‘ä»¬æä¾›äº†ä¸€ç§æ›´å®ç”¨ã€æ›´é«˜æ•ˆçš„æ–¹å¼æ¥å®Œæˆæ­¤ç±»ä»»åŠ¡ã€‚

[![pSKkZcR.png](https://s1.ax1x.com/2023/01/13/pSKkZcR.png)](https://imgse.com/i/pSKkZcR)

æˆ‘ä»¬å¯ä»¥å°†å¤šä¸ªå­—ç¬¦ä¸²æ“ä½œç»„åˆæˆä¸€ä¸ªå•ä¸€çš„é“¾å¼æ“ä½œã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥åœ¨ä¸€è¡Œä»£ç ä¸­ä»åŸå¸‚åˆ—ä¸­æå–stateçš„éƒ¨åˆ†å¹¶å°†å…¶è½¬æ¢ä¸ºå°å†™å­—æ¯ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["city"].str.split(",", expand=True)[1].str.lower())
```

```
0     tx
1     ca
2     tx
3     fl
4     ca
5     ga
Name: 1, dtype: object
```

è€ƒè™‘ä¸€ç§æƒ…å†µï¼Œæˆ‘ä»¬éœ€è¦å°† "field quality "éƒ¨é—¨çš„åç§°æ”¹ä¸º "quality"ã€‚åœ¨`staff`  çš„ `department`åˆ—ä¸­ï¼Œæœ‰å°å†™å’Œå¤§å†™å­—æ¯ã€‚æˆ‘ä»¬é¦–å…ˆéœ€è¦å°†å®ƒä»¬è½¬æ¢ä¸ºå°å†™æˆ–å¤§å†™ï¼Œç„¶åå†è¿›è¡Œæ›¿æ¢ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff["department"].str.lower().replace("field quality","quality"))
```

```
0         accounting
1            quality
2    human resources
3         accounting
4            quality
5        engineering
Name: department, dtype: object
```

ä»start_dateåˆ—ä¸­æå–å¹´ä»½ï¼Œå¹¶å°†å…¶æ•°æ®ç±»å‹æ”¹ä¸ºæ•´æ•°ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

print(staff.query("name > 'John Doe'").start_date.str[:4].astype("int"))
```

```
2    2020
4    2020
Name: start_date, dtype: int64
```

#### ç»ƒä¹  Make the Salary Column Proper

Staffï¼ˆDataFrameï¼‰çš„å·¥èµ„åˆ—ä¸­çš„æ•°å€¼æ˜¯ä»¥å­—ç¬¦ä¸²å½¢å¼å­˜å‚¨çš„ã€‚æˆ‘ä»¬éœ€è¦å°†å…¶è½¬æ¢ä¸ºæ•°å­—æ ¼å¼æ¥è¿›è¡Œè®¡ç®—ã€‚

åœ¨å°†å…¶è½¬æ¢ä¸ºæ•°å­—æ•°æ®ç±»å‹ä¹‹å‰ï¼Œæœ‰ä¸¤ä¸ªé—®é¢˜éœ€è¦æˆ‘ä»¬è§£å†³ã€‚

- æˆ‘ä»¬éœ€è¦å»æ‰å¼€å¤´çš„"$"ç¬¦å·ã€‚
- æˆ‘ä»¬éœ€è¦å»æ‰ä½œä¸ºåƒä½åˆ†éš”ç¬¦çš„","ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

def make_salary_proper():
  try:
    staff["salary_cleaned"] = staff["salary"].str[1:].str.replace(",","")
    staff["salary_cleaned"] = staff["salary_cleaned"].astype("int")
    return list(staff["salary_cleaned"])
  except:
    pass
```

## 5. Pandas Date and Time Data Types

- A specific date or time (`2021-12-10`, `2021-11-25 14:59:00`)
- A fixed interval (`hour`, `week`, `month`).
- A duration (`3 weeks`, `4 hours and 30 minutes`).

Pandasåº“æœ‰å‡ ä¸ªå‡½æ•°å’Œæ–¹æ³•æ¥æœ‰æ•ˆå’Œå®¹æ˜“åœ°å¤„ç†è¿™äº›ä¸åŒçš„å½¢å¼ã€‚ä¸ºæ—¥æœŸå’Œæ—¶é—´å€¼ä½¿ç”¨é€‚å½“çš„æ•°æ®ç±»å‹æ˜¯å¾ˆé‡è¦çš„ã€‚

```python
import pandas as pd

mydate = pd.to_datetime("2021-11-10")

print(mydate)
```

```
2021-11-10 00:00:00
```

å› ä¸ºè¯¥å­—ç¬¦ä¸²åªåŒ…å«æ—¥æœŸä¿¡æ¯ï¼Œæ‰€ä»¥äº§ç”Ÿçš„Timestampçš„æ—¶é—´éƒ¨åˆ†ä¸ºé›¶ã€‚

å¦ä¸€ä¸ªå¸¸ç”¨çš„æ—¥æœŸå’Œæ—¶é—´çš„æ•°æ®ç±»å‹æ˜¯`timedelta[ns]`ï¼Œç”¨äºè¡¨ç¤ºä¸¤ä¸ªæ—¥æœŸæ—¶é—´å¯¹è±¡ä¹‹é—´çš„å·®å¼‚ã€‚

```python
import pandas as pd

first_date = pd.to_datetime("2021-10-10")
second_date = pd.to_datetime("2021-10-02")

diff = first_date - second_date

print(diff)
```

```
8 days 00:00:00
```

`Timedelta`å¯¹è±¡æœ‰ä¸€ä¸ª`days`å±æ€§ï¼Œä»¥æ•´æ•°å½¢å¼è¿”å›å¤©æ•°ã€‚

```python
import pandas as pd

first_date = pd.to_datetime("2021-10-10")
second_date = pd.to_datetime("2021-10-02")

diff = first_date - second_date

print(type(diff))
print("\n")
print(diff.days)
```

```
<class 'pandas._libs.tslibs.timedeltas.Timedelta'>

8
```

æˆ‘ä»¬ä¸€ç›´åœ¨ä½¿ç”¨çš„`staff`åŒ…å«ä¸¤ä¸ªæœ‰æ—¥æœŸä¿¡æ¯çš„åˆ—ï¼š`date_of_birth`å’Œ`start_date`ã€‚ç„¶è€Œï¼Œè¿™äº›åˆ—æ˜¯ä»¥ "å¯¹è±¡ "æ•°æ®ç±»å‹å­˜å‚¨çš„ã€‚ä¸ºäº†å¯¹å®ƒä»¬è¿›è¡Œä¸æ—¥æœŸæœ‰å…³çš„æ“ä½œï¼Œæˆ‘ä»¬éœ€è¦æ”¹å˜å®ƒä»¬çš„æ•°æ®ç±»å‹ï¼Œè¿™å¯ä»¥é€šè¿‡`astype`å‡½æ•°æ¥å®Œæˆã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

staff = staff.astype({
    "date_of_birth": "datetime64[ns]",
    "start_date": "datetime64[ns]",
})

print(staff.dtypes)
```

```
name                     object
city                     object
date_of_birth    datetime64[ns]
start_date       datetime64[ns]
salary                   object
department               object
dtype: object
```

ä½¿ç”¨è¿™äº›æ•°æ®ç±»å‹å¯¹äºåœ¨æ—¥æœŸæ“ä½œä»»åŠ¡ä¸­å……åˆ†åˆ©ç”¨Pandasè‡³å…³é‡è¦ã€‚

### ä»æ—¥æœŸä¸­æå–ä¿¡æ¯

æ— è®ºæ—¶é—´æˆ³å¯¹è±¡çš„ç²¾åº¦å¦‚ä½•ï¼Œå®ƒéƒ½åŒ…å«å¾ˆå¤šä¿¡æ¯ï¼Œæœ‰äº›ä»»åŠ¡éœ€è¦æˆ‘ä»¬æå–ç‰¹å®šçš„ä¿¡æ¯ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å¯¹ä¸€ä¸ªäº§å“çš„æœˆé”€å”®é¢æ„Ÿå…´è¶£ï¼Œæˆ‘ä»¬å°±ä»æ‰€æœ‰äº¤æ˜“çš„æ—¥æœŸä¸­æå–æœˆä»½ã€‚

```python
import pandas as pd

mydate = pd.to_datetime("2021-10-10")

print(f"The year part is {mydate.year}")
print(f"The month part is {mydate.month}")
print(f"The week number part is {mydate.week}")
print(f"The day part is {mydate.day}")
```

```
The year part is 2021
The month part is 10
The week number part is 40
The day part is 10
```

 `month` å’Œ`day` å±æ€§åˆ†åˆ«ç»™æˆ‘ä»¬`Timestamp` å¯¹è±¡çš„æœˆå’Œæ—¥éƒ¨åˆ†ã€‚`week`å±æ€§è¿”å›æ—¥å†ä¸­çš„æ˜ŸæœŸã€‚ä¸€ä¸ª`Timestamp`å¯¹è±¡ä¹Ÿæœ‰ä¸€ä¸ªæ—¶é—´éƒ¨åˆ†å’Œç›¸å…³å±æ€§ã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ªæ›´ç²¾ç¡®çš„å¯¹è±¡å¹¶è®¿é—®ä¸æ—¶é—´æœ‰å…³çš„ä¿¡æ¯ã€‚

æˆ‘ä»¬ä½¿ç”¨äº† f-strings æ¥ä½¿è¾“å‡ºçœ‹èµ·æ¥æ›´æœ‰å¸å¼•åŠ›å’Œä¿¡æ¯é‡ã€‚Python ä¸­çš„ f-strings å…è®¸åœ¨ä¸€ä¸ªå­—ç¬¦ä¸²ä¸­å†™å…¥å˜é‡åã€‚äº§ç”Ÿçš„å­—ç¬¦ä¸²å–è¯¥å˜é‡çš„å€¼ã€‚

```python
import pandas as pd

mydate = pd.to_datetime("2021-10-10 14:30:00")

print(f"The hour part of mydate is {mydate.hour}")
print(f"The minute part of mydate is {mydate.minute}")
print(f"The second part of mydate is {mydate.second}")
```

```
The hour part of mydate is 14
The minute part of mydate is 30
The second part of mydate is 0
```

#### Methods instead of attributes

```python
import pandas as pd

mydate = pd.to_datetime("2021-12-21 00:00:00")

print(f"The date part is {mydate.date()}")
print(f"The day of week is {mydate.weekday()}")
print(f"The name of the month is {mydate.month_name()}")
print(f"The name of the day is {mydate.day_name()}")
```

```
The date part is 2021-12-21
The day of week is 1
The name of the month is December
The name of the day is Tuesday				
```

weekdayæ–¹æ³•è¿”å›ä¸€ä¸ªæ•´æ•°ï¼Œè¡¨ç¤ºä¸€å‘¨ä¸­çš„ä¸€å¤©ï¼Œå…¶ä¸­0æ˜¯æ˜ŸæœŸä¸€ã€‚

- Attribute: `mydate.month`
- Method: `mydate.month_name()`

### The dt Accessor

#### `dt`è®¿é—®å™¨ä¸‹çš„æ–¹æ³•

æˆ‘ä»¬å¯ä»¥ä»¥ç±»ä¼¼çš„æ–¹å¼ä½¿ç”¨`year`andè·å–å¹´ä»½å’Œæ—¶æ®µã€‚`day`é€šè¿‡è®¿é—®å™¨å¯ç”¨çš„å…¶ä»–ä¸€äº›æ–¹æ³•`dt`æ˜¯ï¼š

- `weekday`
- `hour`
- `minute`
- `second`
- `week`ï¼ˆä» 1.1.0 ç‰ˆå¼€å§‹å¼ƒç”¨ï¼‰
- `weekofyear`ï¼ˆä» 1.1.0 ç‰ˆå¼€å§‹å¼ƒç”¨ï¼‰

åœ¨ Pandas 1.1.0 æˆ–æ›´é«˜ç‰ˆæœ¬ä¸­ï¼Œ`isocalendar`æ˜¯ å’Œ çš„éå¸¸æœ‰ç”¨çš„æ›¿ä»£`week`å“`weekofyear`ã€‚å½“åº”ç”¨äºåˆ—æ—¶ï¼Œå®ƒè¿”å›`DataFrame`åŒ…å«å¹´ã€æ—¥å†å‘¨å’Œæ˜ŸæœŸå‡ ä¿¡æ¯çš„ ã€‚

```python
staff["start_date"].dt.isocalendar()
```

### é€šè¿‡æ·»åŠ æ—¶é—´é—´éš”æ¥æ“çºµæ—¥æœŸ

æˆ‘ä»¬å¯ä»¥ç”¨æ¥æ·»åŠ æˆ–å‡å»æ—¥æœŸå’Œæ—¶é—´çš„ä¸€ä¸ª Pandas å‡½æ•°æ˜¯`DateOffset`. å®ƒå¯ä»¥ä¸æ—¥æœŸå’Œæ—¶é—´ä¸€èµ·ä½¿ç”¨ã€‚æˆ‘ä»¬åªéœ€è¦æŒ‡å®šè¦åŠ å‡çš„å•ä½å’Œæ•°é‡å³å¯ã€‚è€ƒè™‘è¿™æ ·ä¸€ç§æƒ…å†µï¼Œæˆ‘ä»¬æƒ³åœ¨å‘˜å·¥å…¥èŒä¸€å¹´åç»™ä»–ä»¬åŠ è–ªã€‚åœ¨å·¥ä½œäººå‘˜ä¸­ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡å‘è¯¥åˆ—`raise_date`æ·»åŠ ä¸€å¹´æ¥åˆ›å»ºä¸€ä¸ªåä¸ºçš„`start_date`åˆ—ã€‚

```python
import pandas as pd

# create the DataFrame
staff = pd.read_csv("staff.csv")

# change the date type
staff = staff.astype({
    "date_of_birth": "datetime64[ns]",
    "start_date": "datetime64[ns]"
})

# create raise_date column
staff["raise_date"] = staff["start_date"] + pd.DateOffset(years=1)

print(staff[["start_date","raise_date"]].head())
```

```
  start_date raise_date
0 2018-08-11 2019-08-11
1 2017-08-24 2018-08-24
2 2020-04-16 2021-04-16
3 2021-02-11 2022-02-11
4 2020-09-01 2021-09-01
```

`DateOffset`åŠŸèƒ½éå¸¸ç®€å•ã€‚æˆ‘ä»¬åªéœ€è¦è°ƒæ•´å•ä½å’Œæ•°é‡ã€‚ä¾‹å¦‚ï¼Œä»¥ä¸‹ä»£ç è¡Œå°†å…­ä¸ªæœˆæ·»åŠ åˆ°`start_date`åˆ—ä¸­ã€‚

```python
staff["start_date"] + pd.DateOffset(months=6)
```

å‡½æ•°ä¸­å¯ä»¥ä½¿ç”¨çš„å•ä½`DataOffset`æœ‰ï¼š

- `years`
- `months`
- `weeks`
- `days`
- `hours`
- `minutes`
- `seconds`
- `microseconds`
- `nanoseconds`

æˆ‘ä»¬æœ‰ä¸¤ç§å‡æ³•è€Œä¸æ˜¯åŠ æ³•çš„é€‰æ‹©ã€‚ä¸€ç§æ˜¯æ”¹`+`to `-`ï¼Œå¦ä¸€ç§æ˜¯åœ¨å‡½æ•°å†…éƒ¨ä½¿ç”¨è´Ÿæ•°ã€‚è®©æˆ‘ä»¬åˆ›å»ºä¸€ä¸ª`Timestamp`å¹¶ä½¿ç”¨è¿™ä¸¤ç§æ–¹æ³•ä»ä¸­å‡å»ä¸¤ä¸ªå°æ—¶ã€‚

```python
import pandas as pd

mytime = pd.Timestamp("2021-12-14 16:50:00")

print("The first method")
print(mytime + pd.DateOffset(hours=-2))

print("\nThe second method")
print(mytime - pd.DateOffset(hours=2))
```

```
The first method
2021-12-14 14:50:00

The second method
2021-12-14 14:50:00
```

#### `Timedelta` åŠŸèƒ½

æ·»åŠ å’Œå‡å»æ—¥æœŸå’Œæ—¶é—´çš„å¦ä¸€ä¸ªé€‰é¡¹æ˜¯`Timedelta`å‡½æ•°ã€‚è¯·æ³¨æ„ï¼Œè¯¥`Timedelta`å‡½æ•°ä¸å†æ”¯æŒ`year`å’Œ`month`å•ä½ï¼Œä½†æˆ‘ä»¬å¯ä»¥å°†å®ƒä¸å…¶ä»–æŒç»­æ—¶é—´ä¸€èµ·ä½¿ç”¨ã€‚

å®ƒçš„ä½¿ç”¨ä¸`DateOffset`å‡½æ•°ç±»ä¼¼ï¼Œåªæ˜¯å‚æ•°è®¾ç½®ä¸åŒã€‚è¯¥`value`å‚æ•°ç”¨äºæŒ‡å®šè¦æ·»åŠ æˆ–å‡å»çš„å•å…ƒæ•°ã€‚è¯¥`unit`å‚æ•°å®šä¹‰äº†æ—¶é—´å•ä½ï¼Œä¾‹å¦‚å°æ—¶å’Œåˆ†é’Ÿã€‚ä»¥ä¸‹å€¼å¯ä¸è¯¥`unit`å‚æ•°ä¸€èµ·ä½¿ç”¨ï¼š

- `W`å¹¶`w`ä»£è¡¨ä¸€å‘¨
- `D`å¹¶`d`ä»£è¡¨ä¸€å¤©
- `H`å¹¶`h`ä»£è¡¨ä¸€ä¸ªå°æ—¶
- `T`ä»£è¡¨ä¸€`t`åˆ†é’Ÿ
- `S`å¹¶`s`ä»£è¡¨ä¸€ç§’é’Ÿ
- `L`å¹¶`l`ä»£è¡¨æ¯«ç§’
- `U`å¹¶`u`ä»£è¡¨ä¸€å¾®ç§’
- `N`å¹¶`n`ä»£è¡¨çº³ç§’

å°† 12 å‘¨æ·»åŠ åˆ°å‡½æ•°ä¸­çš„`start_date`åˆ—

```python
import pandas as pd

# create the DataFrame
staff = pd.read_csv("staff.csv")

# change the date type
staff = staff.astype({
    "date_of_birth": "datetime64[ns]",
    "start_date": "datetime64[ns]"
})

# add 12 weeks
print(staff["start_date"] + pd.Timedelta(value=12, unit="W"))					
```

```
0   2018-11-03
1   2017-11-16
2   2020-07-09
3   2021-05-06
4   2020-11-24
5   2022-01-12
Name: start_date, dtype: datetime64[ns]
```

è¯¥å‡½æ•°çš„ä¸€ä¸ªå¾ˆå¥½çš„ç‰¹æ€§`Timedelta`æ˜¯å®ƒæ¥å—ç”¨äºæŒ‡å®šè¦æ·»åŠ æˆ–å‡å»çš„æŒç»­æ—¶é—´çš„å­—ç¬¦ä¸²ã€‚è¦ä½¿ç”¨è¿™ç§æ ¼å¼ï¼Œå€¼å’Œå•ä½éƒ½å†™æˆä¸€ä¸ªå­—ç¬¦ä¸²ã€‚æˆ‘ä»¬åªéœ€è¦å†™å•ä½ï¼Œå°±åƒ`unit`å‚æ•°ä¸€æ ·ã€‚è®©æˆ‘ä»¬åšä¸ä¸Šé¢ç›¸åŒçš„ç¤ºä¾‹ï¼Œä½†ä½¿ç”¨å­—ç¬¦ä¸²ã€‚

```python
import pandas as pd

# create the DataFrame
staff = pd.read_csv("staff.csv")

# change the date type
staff = staff.astype({
    "date_of_birth": "datetime64[ns]",
    "start_date": "datetime64[ns]"
})

# add 12 weeks
print(staff["start_date"] + pd.Timedelta("12 W"))
```

```
0   2018-11-03
1   2017-11-16
2   2020-07-09
3   2021-05-06
4   2020-11-24
5   2022-01-12
Name: start_date, dtype: datetime64[ns]
```

è¦ä½¿ç”¨å‡½æ•°å‡å»æ—¥æœŸæˆ–æ—¶é—´å€¼`Timestamp`ï¼Œæˆ‘ä»¬å¯ä»¥æ›´æ”¹`+`ä¸º`-`æˆ–åœ¨å‡½æ•°å†…ä½¿ç”¨è´Ÿæ•°ã€‚

### ç»ƒä¹ ï¼šå‘˜å·¥å¹´é¾„

`staff`åŒ…å«`start_date`å’Œåˆ—`date_of_birth`ã€‚æˆ‘ä»¬è¢«è¦æ±‚æ‰¾å‡ºé›‡å‘˜åœ¨ä»–ä»¬è¢«é›‡ç”¨æ—¶çš„å¹´é¾„ã€‚ä¾‹å¦‚ï¼Œå¦‚æœä¸€åå‘˜å·¥å‡ºç”Ÿäº 1991 å¹´å¹¶äº 2021 å¹´å¼€å§‹å·¥ä½œï¼Œåˆ™ç­”æ¡ˆåº”ä¸º 30ã€‚

```python
import pandas as pd

staff = pd.read_csv("staff.csv")

staff = staff.astype({
    "date_of_birth": "datetime64[ns]",
    "start_date": "datetime64[ns]"
})

def find_age():
    try:
        staff["age"] = (staff["start_date"] - staff["date_of_birth"]).dt.days / 365
        # convert to integer
        staff["age"] = staff["age"].astype("int")
        return list(staff["age"])
    except:
        pass
```

## 6. ç¼ºå¤±å€¼ç±»å‹å’Œè¡¨ç¤ºæ–¹æ³•

a`row`ä¸­çš„a`DataFrame`è¡¨ç¤ºä¸€ä¸ªè§‚å¯Ÿå€¼æˆ–ä¸€ä¸ªæ•°æ®ç‚¹ã€‚A`column`æ˜¯è¯¥è§‚å¯Ÿçš„ç‰¹å¾æˆ–å±æ€§ã€‚åœ¨æŸäº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬æ²¡æœ‰æŸäº›è§‚æµ‹å€¼çš„æ‰€æœ‰ç‰¹å¾å€¼ã€‚å‡è®¾æˆ‘ä»¬æœ‰ä¸€ä¸ª`DataFrame`åŒ…å«é“¶è¡Œå®¢æˆ·ä¿¡æ¯çš„ ï¼Œä¾‹å¦‚å§“åã€å¹´é¾„ã€æ”¶å…¥ã€åœ°å€ç­‰ã€‚å¦‚æœæˆ‘ä»¬æ²¡æœ‰å®¢æˆ·çš„å¹´é¾„ä¿¡æ¯ï¼Œåˆ™å°†å…¶è§†ä¸ºç¼ºå¤±å€¼ã€‚

ç¼ºå¤±å€¼æœ¬è´¨ä¸Šæ˜¯æˆ‘ä»¬æ²¡æœ‰çš„æ•°æ®ã€‚a ä¸­å­˜åœ¨ç¼ºå¤±å€¼çš„åŸå› æœ‰å¾ˆå¤š`DataFrame`ï¼Œä¾‹å¦‚è¾“å…¥é”™è¯¯ã€è½¬æ¢è¿‡ç¨‹ä¸­å‘ç”Ÿçš„é—®é¢˜ç­‰ã€‚å¤„ç†ç¼ºå¤±å€¼æ˜¯æ•°æ®æ¸…ç†å’Œé¢„å¤„ç†çš„ä¸€ä¸ªéå¸¸é‡è¦çš„éƒ¨åˆ†ã€‚Pandas åº“æä¾›äº†çµæ´»çš„æ–¹æ³•æ¥æœ‰æ•ˆåœ°å¤„ç†å®ƒä»¬ã€‚

#### ç¼ºå¤±å€¼ç±»å‹

è¦æä¾›ä¸€ä¸ªå¼ºå¤§çš„ç³»ç»Ÿæ¥å¤„ç†ç¼ºå¤±å€¼ï¼Œå¿…é¡»ä½¿ç”¨æ ‡å‡†æ ¼å¼æ¥è¡¨ç¤ºå®ƒä»¬ã€‚a ä¸­çš„æ ‡å‡†ç¼ºå¤±å€¼è¡¨ç¤º`DataFrame`æ˜¯`NaN`. ä½†æ˜¯ï¼Œå®ƒä¸æ•´æ•°å€¼ä¸å…¼å®¹ã€‚å› æ­¤ï¼Œæ¯å½“åˆ—ä¸­æœ‰ä¸€ä¸ª`NaN`å€¼æ—¶`integer`ï¼Œæ•´ä¸ªåˆ—çš„æ•°æ®ç±»å‹éƒ½ä¼šå‘ä¸Šè½¬æ¢ä¸º`float`.

æˆ‘ä»¬éœ€è¦æ˜ç¡®å£°æ˜æ•°æ®ç±»å‹ä¸º`pd.Int64Dtype()`. è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªç¤ºä¾‹æ¥æ¸…æ¥šåœ°è¯´æ˜å·®å¼‚ã€‚æˆ‘ä»¬å°†é¦–å…ˆåˆ›å»ºä¸€ä¸ª`DataFrame`åŒ…å«ä¸€äº›ç¼ºå¤±å€¼çš„ã€‚Pandas åº“æ¥å— Pythonçš„`None`å’Œ NumPyçš„`np.nan`ä½œä¸ºç¼ºå¤±å€¼ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸¤è€…æ¥æŒ‡ç¤ºç¼ºå¤±å€¼ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan],
    "B": [2.4, 6.2, 5.1, np.nan],
    "C": ["foo","zoo","bar", np.nan]
})

print(df)
```

```
     A    B    C
0  1.0  2.4  foo
1  2.0  6.2  zoo
2  3.0  5.1  bar
3  NaN  NaN  NaN
```

ç”±äºæœ€åä¸€è¡Œä¸­ç¼ºå°‘å€¼ï¼Œåˆ—ä¸­çš„å€¼`A`è¢«è½¬æ¢ä¸º`float`å¦‚æœæˆ‘ä»¬å°†æ­¤åˆ—çš„æ•°æ®ç±»å‹æ›´æ”¹ä¸º`pd.Int64Dtype()`ï¼Œåˆ™å€¼å°†ä¸ºæ•´æ•°ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan],
    "B": [2.4, 6.2, 5.1, np.nan],
    "C": ["foo","zoo","bar", np.nan]
})

df["A"] = df["A"].astype(pd.Int64Dtype())

print(df)
```

```
     A    B    C
0    1  2.4  foo
1    2  6.2  zoo
2    3  5.1  bar
3  NaN  NaN  NaN
```

### å¯»æ‰¾ç¼ºå¤±å€¼ `isna` & `notna` 

[![pSKAMMn.png](https://s1.ax1x.com/2023/01/13/pSKAMMn.png)](https://imgse.com/i/pSKAMMn)

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨`isna`æˆ–`notna`å‡½æ•°æ¥æ£€æµ‹ç¼ºå¤±å€¼ã€‚è¯¥`isna`å‡½æ•°è®¡ç®— a ä¸­çš„æ¯ä¸ªå•å…ƒæ ¼`DataFrame`å¹¶è¿”å›`True`ä»¥æŒ‡ç¤ºç¼ºå¤±å€¼ã€‚è®©æˆ‘ä»¬é€šè¿‡ä¸€ä¸ªç¤ºä¾‹æ¥æŸ¥çœ‹å…¶è¾“å‡ºã€‚	

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7]
})

print(df.isna())
```

```
       A      B      C      D
0  False  False   True  False
1  False   True  False   True
2  False  False  False  False
3   True   True  False  False
4  False  False   True  False
```

æˆ‘ä»¬æœ‰ä¸€ä¸ª`True`å’Œ`False`å€¼çš„ç½‘æ ¼ï¼Œå…¶ä¸­`True`å€¼è¡¨ç¤ºç¼ºå¤±å€¼ã€‚ç°å®ç”Ÿæ´»ä¸­çš„æ•°æ®é›†éå¸¸å¤§ï¼Œå› æ­¤æˆ‘ä»¬å¯èƒ½æœ‰`DataFrame`æ•°åƒæˆ–æ•°ç™¾ä¸‡è¡Œã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œè¿”å›ä¸€ä¸ª`DataFrame`å……æ»¡`True`å’Œ`False`å€¼çš„æ•´ä½“æ˜¯æ²¡æœ‰ç”¨çš„ã€‚å¦‚æœæˆ‘ä»¬æƒ³ç»Ÿè®¡åˆ—ä¸­ç¼ºå¤±å€¼çš„ä¸ªæ•°ï¼Œå¯ä»¥é…åˆ`sum`å‡½æ•°ä¸€èµ·ä½¿ç”¨`isna`ã€‚

```python
print(df.isna().sum())
```

```
A    1
B    2
C    2
D    1
dtype: int64
```

æ·»åŠ å¦ä¸€ä¸ª`sum`å‡½æ•°è¿”å› ä¸­ç¼ºå¤±å€¼çš„æ€»æ•°`DataFrame`

```
df.isna().sum().sum()
```

å¦‚æœæˆ‘ä»¬å¯¹æ¯è¡Œç¼ºå¤±å€¼çš„æ•°é‡æ„Ÿå…´è¶£ï¼Œæˆ‘ä»¬ä»ç„¶å¯ä»¥ä½¿ç”¨è¯¥`sum`å‡½æ•°ï¼Œä½†`axis`éœ€è¦å°†å‚æ•°è®¾ç½®ä¸º 1ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7]
})

print(df.isna().sum(axis=1))
```

```
0    1
1    2
2    0
3    2
4    1
dtype: int64
```

æˆ‘ä»¬å¯ä»¥ä½¿ç”¨è¯¥`notna`å‡½æ•°æ¥ç»Ÿè®¡åˆ—æˆ–è¡Œä¸­éç¼ºå¤±å€¼çš„æ•°é‡ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7]
})

print(df.notna().sum())
```

```
A    4
B    3
C    3
D    4
dtype: int64
```

DataFrameåŒ…å«5è¡Œï¼ŒAåˆ—åªæœ‰ä¸€ä¸ªç¼ºå¤±å€¼ï¼Œæ‰€ä»¥è¿™ä¸€åˆ—çš„notnaå‡½æ•°çš„è¾“å‡ºæ˜¯4ã€‚ isnaæˆ–notnaå‡½æ•°æ˜¯æ¢ç´¢æ€§æ•°æ®åˆ†æè¿‡ç¨‹ä¸­çš„ä¸€ä¸ªé‡è¦éƒ¨åˆ†ã€‚ç¼ºå¤±å€¼çš„æ•°é‡å¯¹æˆ‘ä»¬å¦‚ä½•å¤„ç†å®ƒä»¬æœ‰å¾ˆå¤§å½±å“ã€‚

### åˆ é™¤å…·æœ‰ç¼ºå¤±å€¼çš„è¡Œå’Œåˆ—`dropna`

æˆ‘ä»¬åŸºæœ¬ä¸Šæœ‰ä¸¤ä¸ªé€‰é¡¹æ¥å¤„ç†ç¼ºå¤±å€¼ã€‚é¦–å…ˆï¼Œæˆ‘ä»¬å¯ä»¥åˆ é™¤åŒ…å«ç¼ºå¤±å€¼çš„è¡Œæˆ–åˆ—ã€‚è¯¥`dropna`å‡½æ•°ç”¨äºåˆ é™¤å…·æœ‰ç¼ºå¤±å€¼çš„è¡Œå’Œåˆ—ã€‚è¦å‡†ç¡®é«˜æ•ˆåœ°ä½¿ç”¨è¿™ä¸ªå‡½æ•°ï¼Œæˆ‘ä»¬é¦–å…ˆéœ€è¦å­¦ä¹ å®ƒçš„å‚æ•°ã€‚

è¯¥`axis`å‚æ•°ç¡®å®šæ˜¯å¦åˆ é™¤å…·æœ‰ç¼ºå¤±å€¼çš„è¡Œæˆ–åˆ—ã€‚é»˜è®¤å€¼ä¸ºé›¶ï¼Œè¡¨ç¤ºè¡Œã€‚è¯¥`how`å‚æ•°é‡‡ç”¨ä¸¤ä¸ªå€¼ä¹‹ä¸€ï¼š`any`æˆ–`all`ã€‚é»˜è®¤å€¼ä¸º`any`ï¼Œå®ƒä¼šåˆ é™¤è‡³å°‘æœ‰ä¸€ä¸ªç¼ºå¤±å€¼çš„è¡Œæˆ–åˆ—ã€‚å¦‚æœ`all`é€‰æ‹© ï¼Œåˆ™è¦åˆ é™¤çš„è¡Œæˆ–åˆ—å¿…é¡»ç¼ºå°‘æ‰€æœ‰å€¼ã€‚è®©æˆ‘ä»¬çœ‹ä¸€äº›ä¾‹å­æ¥ç†è§£è¿™äº›å‚æ•°æ˜¯å¦‚ä½•ä½¿ç”¨çš„ã€‚æˆ‘ä»¬å°†`DataFrame`åœ¨ä¸‹å›¾ä¸­ä¸ºä»¥ä¸‹ç¤ºä¾‹åˆ›å»º ã€‚

| A    | B    | C    | D    | E    |
| ---- | ---- | ---- | ---- | ---- |
| 1.0  | 2.4  | NaN  | 11.5 | 1    |
| 2.0  | NaN  | foo  | NaN  | 2    |
| 3.0  | 5.1  | zoo  | 6.2  | 3    |
| NaN  | NaN  | bar  | 21.1 | 4    |
| 7.0  | 2.6  | NaN  | 8.7  | 5    |

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7],
    "E": [1, 2, 3, 4, 5]
})

# Drop rows that have at least one missing value
print(df.dropna(axis=0, how="any"))

# Drop columns that have at least one missing value
print(df.dropna(axis=1, how="any"))

# Drop rows that have less than 4 non-missing values

# DataFrameæ²¡æœ‰å……æ»¡ç¼ºå¤±å€¼çš„è¡Œæˆ–åˆ—ï¼Œå› æ­¤å°† how å‚æ•°è®¾ç½®ä¸ºä¸ä¼šallåˆ é™¤ä»»ä½•è¡Œæˆ–åˆ—ã€‚dropnaè¯¥å‡½æ•°çš„å¦ä¸€ä¸ªé‡è¦å‚æ•°æ˜¯threshï¼Œå®ƒå¯ä»¥è®¾ç½®ä¸¢å¼ƒçš„é˜ˆå€¼ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬å°†threshå‚æ•°è®¾ç½®ä¸º 4ï¼Œåˆ™ä¸€è¡Œå¿…é¡»è‡³å°‘æœ‰å››ä¸ªéç¼ºå¤±å€¼æ‰ä¸ä¼šè¢«åˆ é™¤ã€‚æ¢å¥è¯è¯´ï¼Œå°†åˆ é™¤å…·æœ‰ä¸¤ä¸ªæˆ–æ›´å¤šç¼ºå¤±å€¼çš„è¡Œï¼Œå› ä¸ºDataFrame.
print(df.dropna(thresh=4))
```

```
     A    B    C    D  E
2  3.0  5.1  zoo  6.2  3
```

```
   E
0  1
1  2
2  3
3  4
4  5
```

````
     A    B    C     D  E
0  1.0  2.4  NaN  11.5  1
2  3.0  5.1  zoo   6.2  3
4  7.0  2.6  NaN   8.7  5
````

æ‰€æœ‰å‰©ä½™è¡Œä¸­çš„éç¼ºå¤±å€¼çš„æ•°é‡è‡³å°‘ä¸º4ï¼Œè¿™å°±æ˜¯æˆ‘ä»¬çš„é˜ˆå€¼ã€‚åœ¨ä¸Šä¸€ä¸ªä¾‹å­ä¸­ï¼Œæˆ‘ä»¬æ²¡æœ‰ä½¿ç”¨è½´å‚æ•°ï¼Œå› ä¸ºæˆ‘ä»¬å…³æ³¨çš„æ˜¯è¡Œï¼Œè€Œè½´å‚æ•°çš„é»˜è®¤å€¼æ˜¯0ï¼Œè¡¨ç¤ºè¡Œã€‚

#### `inplace`

éœ€è¦æ³¨æ„çš„æ˜¯ï¼Œæˆ‘ä»¬éœ€è¦ä½¿ç”¨`inplace`å‚æ•°å¹¶å°†å…¶è®¾ç½®ä¸º`True`å°†æ›´æ”¹ä¿å­˜åœ¨`DataFrame`. ä»¥ä¸‹ä»£ç `DataFrame`è¡Œåœ¨åˆ é™¤å°‘äºå››ä¸ªéç¼ºå¤±å€¼çš„è¡Œåè¿”å› aã€‚ä½†æ˜¯ï¼Œå®ƒä¸ä¼šä¿®æ”¹`df`. æˆ‘ä»¬æ—¢å¯ä»¥å°†ä¿®æ”¹åçš„èµ‹å€¼`DataFrame`ç»™ä¸€ä¸ªæ–°å˜é‡ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨`inplace`å‚æ•°æ¥ä¿®æ”¹`df`ã€‚`inplace`è®©æˆ‘ä»¬é€šè¿‡å‡ ä¸ªä¾‹å­æ¥æ¼”ç¤ºå‚æ•°çš„ä½¿ç”¨ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7],
    "E": [1, 2, 3, 4, 5]
})

# Drop rows that have less than 4 non-missing values
df.dropna(thresh=4)

print(df)


# Drop rows that have less than 4 non-missing values
df.dropna(thresh=4, inplace=True)

print(df)
```

```
     A    B    C     D  E
0  1.0  2.4  NaN  11.5  1
1  2.0  NaN  foo   NaN  2
2  3.0  5.1  zoo   6.2  3
3  NaN  NaN  bar  21.1  4
4  7.0  2.6  NaN   8.7  5
```

```
     A    B    C     D  E
0  1.0  2.4  NaN  11.5  1
2  3.0  5.1  zoo   6.2  3
4  7.0  2.6  NaN   8.7  5
```

æˆ‘ä»¬ç°åœ¨çœ‹åˆ°æ›´æ”¹å·²ä¿å­˜å¹¶`df`å·²ä¿®æ”¹ã€‚æ˜¯ Pandasä¸­`inplace`ä¸€ä¸ªéå¸¸é‡è¦çš„å‚æ•°ï¼Œå› ä¸ºå®ƒç”¨äºå¤šä¸ªå‡½æ•°ã€‚

### æ›¿æ¢ç¼ºå¤±å€¼`fillna`

ä½†æ˜¯ï¼Œåœ¨è®¸å¤šæƒ…å†µä¸‹ï¼Œä¸¢å¼ƒå¯èƒ½ä¸æ˜¯æœ€ä½³é€‰æ‹©ã€‚å¤„ç†ç¼ºå¤±å€¼çš„å¦ä¸€ç§é€‰æ‹©æ˜¯ä½¿ç”¨å‡½æ•°å°†å®ƒä»¬æ›¿æ¢ä¸ºå®é™…å€¼`fillna`ã€‚

ç”¨äºæ›¿ä»£ç¼ºå¤±å€¼çš„å€¼å–å†³äºæ•°æ®çš„ç‰¹å¾ã€‚æˆ‘ä»¬å¯èƒ½ä¼šé€‰æ‹©ç”¨åˆ—çš„å¹³å‡å€¼æˆ–åˆ—ä¸­å‡ºç°é¢‘ç‡æœ€é«˜çš„å€¼æ¥æ›¿æ¢ç¼ºå¤±å€¼ã€‚æˆ‘ä»¬å°†åˆ›å»ºä»¥ä¸‹å†…å®¹`DataFrame`æ¥æ‰§è¡Œç¤ºä¾‹ã€‚`A`è®©æˆ‘ä»¬ä»ç”¨è¯¥åˆ—çš„å¹³å‡å€¼æ›¿æ¢åˆ—ä¸­çš„ç¼ºå¤±å€¼å¼€å§‹ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7],
    "E": [1, 2, 3, 4, 5]
})

print(df["A"].fillna(value = df["A"].mean()))
```

```
0    1.00
1    2.00
2    3.00
3    3.25
4    7.00
Name: A, dtype: float64
```

ç”¨ä½œæ›¿æ¢çš„å€¼è¢«ä¼ é€’ç»™`value`å‚æ•°ã€‚æ­¤å‚æ•°è¿˜æ¥å— Python `dictionary`ï¼Œå› æ­¤æˆ‘ä»¬å¯ä»¥åœ¨å•ä¸ªæ“ä½œä¸­æ›¿æ¢ä¸åŒåˆ—ä¸­çš„ç¼ºå¤±å€¼ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7],
    "E": [1, 2, 3, 4, 5]
})

# find the replacement values
value_a = df["A"].mean()
value_d = df["D"].mean()

# replace the missing values
print(df.fillna({"A": value_a, "D": value_d}))
```

```
      A    B    C       D  E
0  1.00  2.4  NaN  11.500  1
1  2.00  NaN  foo  11.875  2
2  3.00  5.1  zoo   6.200  3
3  3.25  NaN  bar  21.100  4
4  7.00  2.6  NaN   8.700  5
```

é‡ç”³ä¸€ä¸‹ï¼Œç¡®å®šæ›¿æ¢å€¼å–å†³äºæ•°æ®çš„ç‰¹æ€§ã€‚ä¾‹å¦‚ï¼Œå¦‚æœæˆ‘ä»¬çš„æ•°æ®åŒ…å«æ¯æ—¥è‚¡ç¥¨ä»·æ ¼ï¼Œåˆ™ç”¨å‰ä¸€ä¸ªæˆ–ä¸‹ä¸€ä¸ªå€¼å¡«å……ç¼ºå¤±å€¼æ¯”ä½¿ç”¨å¹³å‡å€¼æ›´ä¼˜åŒ–ã€‚è¿™æ˜¯æ—¶é—´åºåˆ—æ•°æ®ä¸­å¸¸ç”¨çš„æ–¹æ³•ã€‚è¯¥`fillna`å‡½æ•°ä½¿ç”¨å‚æ•°è½»æ¾æ‰§è¡Œæ­¤æ“ä½œ`method`ã€‚

- `method = "bfill"`: Replace missing values backwardï¼Œæ„æ€æ˜¯ä¸€ä¸ªç¼ºå¤±å€¼è¢«åé¢çš„å€¼ä»£æ›¿ã€‚
- `method = "ffill"`: Replace missing values forwardï¼Œæ„æ€æ˜¯å°†ç¼ºå¤±å€¼æ›¿æ¢ä¸ºä¹‹å‰çš„å€¼ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, 3, np.nan, 7],
    "B": [2.4, np.nan, 5.1, np.nan, 2.6],
    "C": [np.nan, "foo","zoo","bar", np.nan],
    "D": [11.5, np.nan, 6.2, 21.1, 8.7],
    "E": [1, 2, 3, 4, 5]
})

print("Filling backward")
print(df["A"].fillna(method="bfill"))

print("\nFilling forward")
print(df["A"].fillna(method="ffill"))
```

```
Filling backward
0    1.0
1    2.0
2    3.0
3    7.0
4    7.0
Name: A, dtype: float64

Filling forward
0    1.0
1    2.0
2    3.0
3    3.0
4    7.0
Name: A, dtype: float64
```

å¦‚æœæœ‰è¿ç»­çš„ç¼ºå¤±å€¼ï¼Œæˆ‘ä»¬ä½¿ç”¨å‰å‘æˆ–åå‘å¡«å……ï¼Œ`fillna`å‡½æ•°ä¼šè¿ç»­æ›¿æ¢æ‰€æœ‰ç¼ºå¤±å€¼ã€‚**æˆ‘ä»¬å¯ä»¥é€šè¿‡å‚æ•°æ¥é™åˆ¶å‰å‘å’Œåå‘æ›¿æ¢å¡«å……çš„ç¼ºå¤±å€¼çš„ä¸ªæ•°`limit`**ã€‚è®©æˆ‘ä»¬çœ‹ä¸€ä¸ªç®€å•çš„ä¾‹å­æ¥æ¼”ç¤º`limit`å‚æ•°æ˜¯å¦‚ä½•å·¥ä½œçš„ã€‚

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "A": [1, 2, np.nan, np.nan, 8]
})

print("Without the limit parameter")
print(df.fillna(method="bfill"))

print("\nWith the limit parameter")
print(df.fillna(method="bfill", limit=1))
```

```
Without the limit parameter
     A
0  1.0
1  2.0
2  8.0
3  8.0
4  8.0

With the limit parameter
     A
0  1.0
1  2.0
2  NaN
3  8.0
4  8.0
```

å½“æˆ‘ä»¬å°†`limit`å‚æ•°è®¾ç½®ä¸ºä¸€ä¸ªæ—¶ï¼Œåªæœ‰ä¸€ä¸ªå€¼è¢«å‘åæ›¿æ¢ã€‚å°±åƒ`dropna`å‡½æ•°ä¸€æ ·ï¼Œæˆ‘ä»¬éœ€è¦è®¾ç½®`inplace`å‚æ•°çš„å€¼ï¼Œ`True`ä»¥ä¿å­˜å¯¹åŸå§‹æ–‡ä»¶çš„æ›´æ”¹`DataFrame`ã€‚

#### ç»ƒä¹ ï¼šå¡«è¡¥ç¼ºå¤±å€¼

æˆ‘ä»¬æœ‰ä»¥ä¸‹`DataFrame`ä¸¤åˆ—å’Œåè¡Œã€‚æˆ‘ä»¬æƒ³`measurement`ç”¨å®ƒä»¬ä»¥å‰çš„å€¼å¡«å……åˆ—ä¸­ç¼ºå¤±çš„å€¼ï¼Œä½†æˆ‘ä»¬åªå…è®¸ä½¿ç”¨æ­¤æ–¹æ³•å¡«å……ä¸¤ä¸ªè¿ç»­çš„å€¼ã€‚å…¶ä½™çš„éœ€è¦ç”¨è¯¥åˆ—çš„å¹³å‡å€¼å¡«å……ã€‚

|  No  |    Date    | Measurement |
| :--: | :--------: | :---------: |
|  0   | 2021-10-01 |    16.0     |
|  1   | 2021-10-02 |    13.0     |
|  2   | 2021-10-03 |    14.0     |
|  3   | 2021-10-04 |    12.0     |
|  4   | 2021-10-05 |     NaN     |
|  5   | 2021-10-06 |     NaN     |
|  6   | 2021-10-07 |     NaN     |
|  7   | 2021-10-08 |     8.0     |
|  8   | 2021-10-09 |     7.0     |
|  9   | 2021-10-10 |     5.0     |

```python
import numpy as np
import pandas as pd

df = pd.DataFrame({
    "Date": pd.date_range(start="2021-10-01", periods=10),
    "Measurement": [16, 13, 14, 12, np.nan, np.nan, np.nan, 8, 7, 5]
})

def fill_missing_values():
  try:
    
    df.fillna(method="ffill", limit=2, inplace=True)
    df.fillna(value=df["Measurement"].mean(), inplace=True)
    return list(df["Measurement"])
    
  except:
    pass
```



# ğŸ”—å‚è€ƒ

https://www.runoob.com/python/att-list-index.html